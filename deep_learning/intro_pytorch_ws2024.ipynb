{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c11ab35",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n",
    "\n",
    "Partly based on https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f5928",
   "metadata": {},
   "source": [
    "## What is Pytorch?\n",
    "\n",
    "- Numpy\n",
    "- ... with GPU support\n",
    "- Automatic differentiation engine\n",
    "- Library for neural network components\n",
    "- Library for optimization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa32dd8",
   "metadata": {},
   "source": [
    "## Parallels between Pytorch and Numpy\n",
    "\n",
    "If you install a current version of pytorch, you should have version `2.5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a3cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bb1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f8165",
   "metadata": {},
   "source": [
    "The equivalent to the numpy array is the [torch Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaa8704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "\n",
    "x_np = np.array(data)\n",
    "x = torch.Tensor(data)\n",
    "\n",
    "print(x_np)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa14843",
   "metadata": {},
   "source": [
    "Many tensor creation operations have the same name like numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707d19f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function ones_like at 0x0000022CCCBBC7F0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rows = 5\n",
    "n_cols = 10\n",
    "\n",
    "print(torch.zeros((n_rows, n_cols)))\n",
    "print(np.zeros((n_rows, n_cols)))\n",
    "\n",
    "torch.ones\n",
    "np.ones\n",
    "\n",
    "torch.ones_like\n",
    "np.ones_like\n",
    "\n",
    "#...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccaee0",
   "metadata": {},
   "source": [
    "Indexing works the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b255b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]]\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n",
      "[[ 6  7  8  9 10 11]\n",
      " [18 19 20 21 22 23]]\n",
      "tensor([[ 6,  7,  8,  9, 10, 11],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "x_np = np.arange(24).reshape(4, 6)\n",
    "print(x_np)\n",
    "\n",
    "x = torch.arange(24).reshape(4, 6)\n",
    "print(x)\n",
    "\n",
    "print(x_np[1:5:2, :])\n",
    "print(x[1:5:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfd2f8",
   "metadata": {},
   "source": [
    "... but there are some differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbc880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.int32'>\n",
      "tensor(0) <class 'torch.Tensor'>\n",
      "0 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(x_np[0,0], type(x_np[0, 0]))\n",
    "\n",
    "print(x[0, 0], type(x[0, 0]))\n",
    "print(x[0, 0].item(), type(x[0, 0].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019d5c2",
   "metadata": {},
   "source": [
    "We can get the shape the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7ded4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6)\n",
      "torch.Size([4, 6])\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(x_np.shape)\n",
    "print(x.shape)\n",
    "\n",
    "print(x.size(dim=1))\n",
    "print(x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f74a1",
   "metadata": {},
   "source": [
    "You can create a tensor from an array and an array from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c312a50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]], dtype=torch.int32)\n",
      "[[-1000     1     2     3     4     5]\n",
      " [    6     7     8     9    10    11]\n",
      " [   12    13    14    15    16    17]\n",
      " [   18    19    20    21    22    23]]\n",
      "tensor([[-1000,     1,     2,     3,     4,     5],\n",
      "        [    6,     7,     8,     9,    10,    11],\n",
      "        [   12,    13,    14,    15,    16,    17],\n",
      "        [   18,    19,    20,    21,    22,    23]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(x_np)\n",
    "print(x)\n",
    "\n",
    "x_np[0,0] = -1000\n",
    "\n",
    "print(x_np)\n",
    "# what else has changed?\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c88dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1000     1     2     3     4     5]\n",
      " [    6     7     8     9    10    11]\n",
      " [   12    13    14    15    16    17]\n",
      " [   18    19    20    21    22    23]]\n"
     ]
    }
   ],
   "source": [
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf4396",
   "metadata": {},
   "source": [
    "Operations work just like numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a586fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((4,4))\n",
    "\n",
    "print(x @ x)  # matrix multiplication\n",
    "x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550e258",
   "metadata": {},
   "source": [
    "Some additional in-place operations that save memory. Marked with `_` at the end of the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1241d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x + x  # creates a new tensor, x will remain as is\n",
    "print(x)\n",
    "x.add_(x)  # in place, x will be modified\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be74b5",
   "metadata": {},
   "source": [
    "## GPU support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b7b86",
   "metadata": {},
   "source": [
    "A Graphic Processing Unit (GPU) can be thought of as a processor with _many_ cores (think thousands), which however are limited in their instruction set.\n",
    "[Kevin Krewell, 2009](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/) gives the following comparison:\n",
    "| CPU | GPU |\n",
    "| -------- | -------- |\n",
    "| Central Processing Unit | Graphics Processing Unit |\n",
    "| Several cores | Many cores |\n",
    "| Low latency | High throughput |\n",
    "| Good for serial processing | Good for parallel processing |\n",
    "| Can do a handful of operations at once | Can do thousands of operations at once |\n",
    "\n",
    "For example, the recent Nvidia H100 GPU has 456 \"Tensor Cores\", which are specifically designed for machine learning workloads.\n",
    "\n",
    "In deep learning, highly parallelizable linear algebra operations are everywhere, which makes a GPU a suitable accelerator for deep learning tasks.\n",
    "Speedup can be up to two magnitudes.\n",
    "\n",
    "*To use GPUs with Pytorch, you need to install the correct version.*\n",
    "* with CUDA for Nvidia GPUs\n",
    "* with ROCm for AMD GPUs\n",
    "\n",
    "CUDA is software from NVIDIA to make use of GPUs easier (for developers, we do not directly interface with it).\n",
    "Nvidia dominates the market, so typically we move data to a \"CUDA\" device to use GPU.\n",
    "\n",
    "\n",
    "AMD has similar software (ROCm), though less mature. \n",
    "You can install pytorch with ROCm support, but you still move data to GPU via a \"cuda\" device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea7c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # to check whether pytorch was compiled with GPU support and whether a GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf861020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c329209",
   "metadata": {},
   "source": [
    "How can we use this with tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec9a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5, device=device)\n",
    "\n",
    "x = torch.arange(5).to(device)\n",
    "\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6dc3a0",
   "metadata": {},
   "source": [
    "Operations require both tensors to be on the same device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c7c71a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m5\u001b[39m, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m+\u001b[39m y\n",
      "File \u001b[1;32mc:\\Users\\klabun01\\.conda\\envs\\idl23\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5, device=torch.device(\"cuda\"))\n",
    "\n",
    "y = torch.arange(5, device=torch.device(\"cpu\"))\n",
    "\n",
    "x + y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1a977",
   "metadata": {},
   "source": [
    "## What is Pytorch?\n",
    "\n",
    "- Numpy [Done]\n",
    "- ... with GPU support [Done]\n",
    "- Automatic differentiation engine\n",
    "- Library for neural network components\n",
    "- Library for optimization methods\n",
    "\n",
    "## Example: Linear Regression\n",
    "\n",
    "We are given inputs $x_i \\in \\R^p$ and targets $y_i \\in \\R$ for $i \\in {1, \\dots, n}$.\n",
    "\n",
    "For example: $x_i$ consists of measurements of temperature, humidity, rainfall, etc., and $y_i$ is the amount of ice cream sold at a particular shop.\n",
    "\n",
    "A linear regression model models the sales as a function of the form:\n",
    "$$y_i = f(x_i, w) = w_o + \\sum_{k=1}^p w_k x_{ik}$$\n",
    "with $w = [w_0, \\dots, w_p]$ parameters.\n",
    "\n",
    "How to choose the parameters (make the predictions fit the real data)?\n",
    "\n",
    "Define an error function $$E(w)= \\sum_{i=1}^n (f(x_i, w) - y_i)^2$$ and minimize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4541e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b5397",
   "metadata": {},
   "source": [
    "(Synthetic) ground truth data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ea708",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = 10 + 20 * torch.rand((30,)).to(dtype=torch.float)\n",
    "x = x.reshape(-1, 1)\n",
    "y = 2.7 * x + 2 * torch.randn_like(x) + 5\n",
    "\n",
    "# Always: visualize data!\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6a058",
   "metadata": {},
   "source": [
    "Linear regression implementation (numpy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self) -> None:\n",
    "        self.w = None\n",
    "\n",
    "    def _add_constant(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Add a constant column to a matrix\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Original data matrix\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Original data matrix with concatenated column of all ones.\n",
    "        \"\"\"\n",
    "        return np.hstack((X, np.ones((len(X), 1))))\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"Fit the parameters of the model to the data\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): features\n",
    "            y (np.ndarray): targets\n",
    "        \"\"\"\n",
    "        X = self._add_constant(X)\n",
    "        self.w = np.linalg.inv(X.T @ X) @ X.T @ y  # there is also np.linalg.pinv\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use parameters to predict values\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): features\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: predicted targets\n",
    "        \"\"\"\n",
    "        X = self._add_constant(X)\n",
    "        return X @ self.w\n",
    "\n",
    "X = x.numpy()\n",
    "model = LinearRegression()\n",
    "model.fit(X, y.numpy())\n",
    "preds = model.predict(X)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "sort_idx = x.flatten().argsort()\n",
    "plt.plot(x[sort_idx,0], preds[sort_idx,0], color=\"red\", label=\"Predictions\")\n",
    "plt.legend()\n",
    "\n",
    "model.w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e95ce1",
   "metadata": {},
   "source": [
    "We could solve this here, but in general:\n",
    "- Calculating the gradient manually is cumbersome\n",
    "- Not all equation systems have analytical solutions\n",
    "\n",
    "Hence, Pytorch helps us by\n",
    "- computing gradients automatically\n",
    "- and giving us the tools to optimize functions numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca81398",
   "metadata": {},
   "source": [
    "### Automatic Differentiation\n",
    "\n",
    "Pytorch keeps track of the so-called \"computation graph\" (We will come back to this in a few weeks).\n",
    "This graph records all the operations done on (specific) tensors, thus traces the function that the tensors are used in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v  = torch.ones(3)\n",
    "print(v.requires_grad)\n",
    "\n",
    "v  = torch.ones(3, requires_grad=True)\n",
    "print(v.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc490f",
   "metadata": {},
   "source": [
    "Let's define a simple function: $c (v) = \\sum_i (v_i-2)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = v - 2\n",
    "b = a**2\n",
    "c = b.sum()\n",
    "\n",
    "print(c)\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55de6f",
   "metadata": {},
   "source": [
    "We calculate the gradients $\\nabla_v c = [\\partial c/\\partial v_1, \\dots]^T$ by calling `.backward()` on `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e2349",
   "metadata": {},
   "source": [
    "Now the `.grad` attribute is populated with the gradient values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d44d2",
   "metadata": {},
   "source": [
    "### Numerical Optimization\n",
    "\n",
    "How does having the gradient help us in any way?\n",
    "\n",
    "_Gradient descent_ (GD) is a method to optimize differentiable functions (details in the coming weeks).\n",
    "All GD needs are the gradient values of the parameters, and access to the parameters itself. We have both with pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn  # the part of torch with all neural network components (and loss functions)\n",
    "\n",
    "# automatically registers parameters of layers inside it as trainable (i.e., requires_grad=True)\n",
    "# needs to methods: __init__ to describe what components the NN consists of, and forward to describe how they interact\n",
    "class LinearRegressionPytorch(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(n_features, 1, bias=True)  # Ax+b\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model_pt = LinearRegressionPytorch(x.size(-1))\n",
    "for param_name, param in model_pt.named_parameters():\n",
    "    print(param_name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e08adb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_pt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c54c9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.sum().backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_pt.linear.weight.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76bad2",
   "metadata": {},
   "source": [
    "Whenever you use the model, the operations are recorded, so that the gradient can be computed later.\n",
    "Some operations should not be tracked, e.g., evaluation on a validation data set.\n",
    "Also, the recording is not free: it takes up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87643d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt = LinearRegressionPytorch(x.size(-1))\n",
    "\n",
    "# the context manager temporarily turns off recording of operations\n",
    "with torch.no_grad():\n",
    "    out = model_pt(x)\n",
    "    loss = out.sum()\n",
    "    # loss.backward()\n",
    "print(model_pt.linear.weight.grad)\n",
    "\n",
    "out = model_pt(x)\n",
    "loss = out.sum()\n",
    "loss.backward()\n",
    "print(model_pt.linear.weight.grad)\n",
    "\n",
    "\n",
    "# You can use the function decorator for functions that should influence gradients\n",
    "@torch.no_grad()\n",
    "def eval(model, x_val, y_val):\n",
    "    pred = model(x_val)\n",
    "    return (pred - y_val).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d882700",
   "metadata": {},
   "source": [
    "A minimal training loop looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt = LinearRegressionPytorch(x.size(-1))\n",
    "\n",
    "preds_epochs = []\n",
    "\n",
    "optimizer = torch.optim.SGD(model_pt.parameters(), lr=5e-4)  # register the parameters with the optimization method\n",
    "loss_func = nn.MSELoss()\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    output = model_pt(x)  # Step 1: forward pass\n",
    "    loss = loss_func(output, y)  # Step 2: compute loss\n",
    "    optimizer.zero_grad()  # Step 3 : .grad attributes = 0\n",
    "    loss.backward()  # Step 4: Compute gradients (populate .grad attributes again)\n",
    "    optimizer.step()  # Step 5: optimization step\n",
    "\n",
    "    print(f\"{epoch=}: loss={loss.item()}\")\n",
    "    preds_epochs.append(output.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1210462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cmap = mpl.colormaps.get_cmap(\"viridis\")\n",
    "label_every_n_epoch = 3\n",
    "ax.scatter(x.view(-1), y.view(-1), color=\"blue\")\n",
    "for epoch, preds in enumerate(preds_epochs):\n",
    "    sort_idx = x.flatten().argsort()\n",
    "    if epoch % label_every_n_epoch == 0:\n",
    "        kwargs = dict(\n",
    "            color=cmap(epoch / len(preds_epochs)), label=f\"Predictions ({epoch=})\"\n",
    "        )\n",
    "    else:\n",
    "        kwargs = dict(\n",
    "            color=cmap(epoch / len(preds_epochs))\n",
    "        )\n",
    "\n",
    "    ax.plot(\n",
    "        x[sort_idx, 0], preds[sort_idx, 0], **kwargs,\n",
    "    )\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5890a3",
   "metadata": {},
   "source": [
    "There is more, which we will cover in the upcoming weeks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
